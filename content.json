{"meta":{"title":"huskyui","subtitle":"","description":"","author":"huskyui","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"leetcode-22括号生成","slug":"leetcode-22括号生成","date":"2020-11-14T09:00:33.378Z","updated":"2020-11-14T08:57:50.429Z","comments":true,"path":"2020/11/14/leetcode-22括号生成/","link":"","permalink":"http://yoursite.com/2020/11/14/leetcode-22%E6%8B%AC%E5%8F%B7%E7%94%9F%E6%88%90/","excerpt":"","text":"//数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。 // // // // 示例： // // 输入：n = 3 //输出：[ // &quot;((()))&quot;, // &quot;(()())&quot;, // &quot;(())()&quot;, // &quot;()(())&quot;, // &quot;()()()&quot; // ] // // Related Topics 字符串 回溯算法 // 👍 1356 👎 0 import java.util.ArrayList; import java.util.List; //leetcode submit region begin(Prohibit modification and deletion) class Solution { // 全局变量 private List&lt;String&gt; list = new ArrayList&lt;&gt;(); public List&lt;String&gt; generateParenthesis(int n) { // 生成题目当然不能是for循环生成 dfs(0, 0, n, &quot;&quot;); return list; } public void dfs(int left, int right, int n, String path) { // 排除掉 括号数量太多的选手 if (left &gt; n || right &gt; n) { return; } // 如果右边大于左边，那么就删除当前选手 if (right&gt;left) { return; } // final champion if (left + right == 2 * n) { list.add(path); return; } dfs(left + 1, right, n, path + &quot;(&quot;); dfs(left, right + 1, n, path + &quot;)&quot;); } } //leetcode submit region end(Prohibit modification and deletion)","categories":[],"tags":[]},{"title":"zookeeper-2","slug":"zookeeper-2","date":"2020-04-24T10:13:11.000Z","updated":"2020-04-28T10:15:53.050Z","comments":true,"path":"2020/04/24/zookeeper-2/","link":"","permalink":"http://yoursite.com/2020/04/24/zookeeper-2/","excerpt":"","text":"java连接pom 123456789101112131415161718192021222324252627282930 &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;!-- 在提交到github的时候，提示让使用3.4.14以后的版本 --&gt;&lt;!-- &lt;version&gt;[3.4.14,)&lt;/version&gt; --&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.zookeeper&lt;/groupId&gt; &lt;artifactId&gt;zookeeper&lt;/artifactId&gt; &lt;version&gt;3.4.14&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/log4j/log4j --&gt; &lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.16&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-api --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.6.1&lt;/version&gt; &lt;/dependency&gt;","categories":[],"tags":[]},{"title":"zookeeper-1","slug":"zookeeper-1","date":"2020-04-20T09:16:27.000Z","updated":"2020-04-24T10:11:55.584Z","comments":true,"path":"2020/04/20/zookeeper-1/","link":"","permalink":"http://yoursite.com/2020/04/20/zookeeper-1/","excerpt":"","text":"简介123456789101112131415161718192021222324252627282930313233343536373839404142434445464748ZooKeeper: A Distributed Coordination Service for Distributed ApplicationszooKeeper:一个分布式应用的分布式协调服务ZooKeeper is a distributed, open-source coordination service for distributed applications. It exposes a simple set of primitives that distributed applications can build upon to implement higher level services for synchronization, configuration maintenance, and groups and naming. It is designed to be easy to program to, and uses a data model styled after the familiar directory tree structure of file systems. It runs in Java and has bindings for both Java and C.zooKeeper是一个分布式应用的分布式，开源，协调服务。它提供了一组简单的原语，分布式应用可以在这些原语基础上实现更高级的服务，用于同步，配置维护，组合命名。它被设计易于使用，并使用了风格和文件系统相似的数据模型。它在java运行，并具有java和c绑定。Coordination services are notoriously hard to get right. They are especially prone to errors such as race conditions and deadlock. The motivation behind ZooKeeper is to relieve distributed applications the responsibility of implementing coordination services from scratch.协调服务是出了名的难写。他们特别容易出现竞争条件和死锁错误。zookeeper背后的动机是为了减少分布式应用程序从头实现协调服务的责任。Design GoalsZooKeeper is simple. ZooKeeper allows distributed processes to coordinate with each other through a shared hierarchical namespace which is organized similarly to a standard file system. The namespace consists of data registers - called znodes, in ZooKeeper parlance - and these are similar to files and directories. Unlike a typical file system, which is designed for storage, ZooKeeper data is kept in-memory, which means ZooKeeper can achieve high throughput and low latency numbers.zooKeeper是简单的。zooKeeper允许分布式进程通过共享的层次命名空间相互协调，该命名空间类似于标准文件系统。命名空间由数据寄存器注册，用zooKeeper的话说叫znodes，类似于文件系统中的目录和文件。不像典型的文件系统，zookeeper是设计用于保存在内存中，意味着zooKeeper可以实现高吞吐量和低延迟率。The ZooKeeper implementation puts a premium on high performance, highly available, strictly ordered access. The performance aspects of ZooKeeper means it can be used in large, distributed systems. The reliability aspects keep it from being a single point of failure. The strict ordering means that sophisticated synchronization primitives can be implemented at the client.ZooKeeper实施对高性能，高可用性，严格有序访问加以重视。 ZooKeeper的性能方面意味着它可以在大型的分布式系统中使用。 可靠性方面使它不会成为单点故障。 严格排序意味着可以在客户端上实现复杂的同步原语。ZooKeeper is replicated. Like the distributed processes it coordinates, ZooKeeper itself is intended to be replicated over a set of hosts called an ensemble.ZooKeeper是复制的。与它所协调的分布式进程一样，ZooKeeper本身也打算在一组称为集合的主机上进行复制。The servers that make up the ZooKeeper service must all know about each other. They maintain an in-memory image of state, along with a transaction logs and snapshots in a persistent store. As long as a majority of the servers are available, the ZooKeeper service will be available.组成ZooKeeper服务的服务器必须相互了解。它们在内存中维护状态映像，以及持久存储中的事务日志和快照。只要大多数服务器可用，ZooKeeper服务就可用。Clients connect to a single ZooKeeper server. The client maintains a TCP connection through which it sends requests, gets responses, gets watch events, and sends heart beats. If the TCP connection to the server breaks, the client will connect to a different server.客户端连接到单个ZooKeeper服务器。客户端维护一个TCP连接，通过它发送请求、获取响应、获取监视事件和发送心跳。如果到服务器的TCP连接中断，客户机将连接到另一台服务器。ZooKeeper is ordered. ZooKeeper stamps each update with a number that reflects the order of all ZooKeeper transactions. Subsequent operations can use the order to implement higher-level abstractions, such as synchronization primitives.Zookeeper是有序的。ZooKeeper用一个数字来标记每个更新，这个数字反映了所有ZooKeeper事务的顺序。后续操作可以使用该顺序实现更高级别的抽象，比如同步原语。ZooKeeper is fast. It is especially fast in &quot;read-dominant&quot; workloads. ZooKeeper applications run on thousands of machines, and it performs best where reads are more common than writes, at ratios of around 10:1.ZooKeeper很快。在“以读取为主”的工作负载中，它的速度特别快。ZooKeeper应用程序运行在数千台机器上，当读操作比写操作更常见时，它的性能最好，比率约为10:1。Data model and the hierarchical namespaceThe namespace provided by ZooKeeper is much like that of a standard file system. A name is a sequence of path elements separated by a slash (&#x2F;). Every node in ZooKeeper&#39;s namespace is identified by a path.数据模型和分层名称空间ZooKeeper提供的名称空间与标准文件系统的名称空间非常相似。 名称是由斜杠（&#x2F;）分隔的一系列路径元素。 ZooKeeper命名空间中的每个节点都由路径标识。Nodes and ephemeral nodesUnlike standard file systems, each node in a ZooKeeper namespace can have data associated with it as well as children. It is like having a file-system that allows a file to also be a directory. (ZooKeeper was designed to store coordination data: status information, configuration, location information, etc., so the data stored at each node is usually small, in the byte to kilobyte range.) We use the term znode to make it clear that we are talking about ZooKeeper data nodes.Znodes maintain a stat structure that includes version numbers for data changes, ACL changes, and timestamps, to allow cache validations and coordinated updates. Each time a znode&#39;s data changes, the version number increases. For instance, whenever a client retrieves data it also receives the version of the data.The data stored at each znode in a namespace is read and written atomically. Reads get all the data bytes associated with a znode and a write replaces all the data. Each node has an Access Control List (ACL) that restricts who can do what.ZooKeeper also has the notion of ephemeral nodes. These znodes exists as long as the session that created the znode is active. When the session ends the znode is deleted.节点和短暂节点与标准文件系统不同，ZooKeeper命名空间中的每个节点都可以具有与其关联的数据以及子节点。 就像拥有一个文件系统一样，该文件系统也允许文件成为目录。 （ZooKeeper旨在存储协调数据：状态信息，配置，位置信息等，因此存储在每个节点上的数据通常很小，在字节到千字节范围内。）我们使用术语znode来明确表示 在谈论ZooKeeper数据节点。Znodes维护一个统计信息结构，其中包括用于数据更改，ACL更改和时间戳的版本号，以允许进行缓存验证和协调更新。 znode的数据每次更改时，版本号都会增加。 例如，每当客户端检索数据时，它也接收数据的版本。原子地读取和写入存储在名称空间中每个znode上的数据。 读取将获取与znode关联的所有数据字节，而写入将替换所有数据。 每个节点都有一个访问控制列表（ACL），用于限制谁可以执行操作。ZooKeeper还具有短暂节点的概念。 只要创建znode的会话处于活动状态，这些znode就存在。 会话结束时，将删除znode。Conditional updates and watchesZooKeeper supports the concept of watches. Clients can set a watch on a znode. A watch will be triggered and removed when the znode changes. When a watch is triggered, the client receives a packet saying that the znode has changed. If the connection between the client and one of the ZooKeeper servers is broken, the client will receive a local notification.条件更新和手表ZooKeeper支持手表的概念。客户端可以在znode上设置手表。当znode发生变化时，将触发并删除一个手表。当一个手表被触发时，客户端会收到一个数据包，说znode已经改变了。如果客户端和一个ZooKeeper服务器之间的连接断开，客户端将收到一个本地通知。 安装zookeeperStandalone Operation 123456789101112131.下载zookeeper，通过fileZile上传上去tar -zxvf apache-zookeeper-3.6.0-bin.tar.gz2.安装java3.将解压后的文件名重命名mv apache-zookeeper-3.6.0-bin zookeeper并移动至&#x2F;usr&#x2F;libmv &#x2F;tmp&#x2F;zookeeper&#x2F; &#x2F;usr&#x2F;libStandalone Operation单击演示4.生成一个zoo.cfgvi conf zoo.cfg​ tickTime=2000dataDir=/var/lib/zookeeperclientPort=2181​```启动sh bin/zkServer.sh start5.测试sh bin/zkCli.sh -server 127.0.0.1:2181ls /[ zookeeper]Next, create a new znode by running create /zk_test my_data. This creates a new znode and associates the string “my_data” with the node. You should see:[zkshell: 9] create /zk_test my_dataCreated /zk_test[zk: 127.0.0.1:2181(CONNECTED) 0] ls /[zk_test, zookeeper][zk: 127.0.0.1:2181(CONNECTED) 3] get /zk_testmy_data [zk: 127.0.0.1:2181(CONNECTED) 5] get -s /zk_testmy_datacZxid = 0x3ctime = Wed Apr 22 18:33:23 CST 2020mZxid = 0x3mtime = Wed Apr 22 18:33:23 CST 2020pZxid = 0x3cversion = 0dataVersion = 0aclVersion = 0ephemeralOwner = 0x0dataLength = 7numChildren = 0[zk: 127.0.0.1:2181(CONNECTED) 6] set /zk_test junk[zk: 127.0.0.1:2181(CONNECTED) 7] get -s /zk_testjunkcZxid = 0x3ctime = Wed Apr 22 18:33:23 CST 2020mZxid = 0x7mtime = Fri Apr 24 17:48:13 CST 2020pZxid = 0x3cversion = 0dataVersion = 1aclVersion = 0ephemeralOwner = 0x0dataLength = 4numChildren = 0可以看到mTime被改变了，以及znode的值[zk: 127.0.0.1:2181(CONNECTED) 8] delete /zk_test删除/zk_test[zk: 127.0.0.1:2181(CONNECTED) 9] get -s /zk_testorg.apache.zookeeper.KeeperException$NoNodeException: KeeperErrorCode = NoNode for /zk_test 集群模式 后续再介绍","categories":[],"tags":[]},{"title":"springcloud-gateway","slug":"springcloud-gateway","date":"2020-04-08T06:59:29.000Z","updated":"2020-04-17T02:33:28.728Z","comments":true,"path":"2020/04/08/springcloud-gateway/","link":"","permalink":"http://yoursite.com/2020/04/08/springcloud-gateway/","excerpt":"","text":"在写之前，想写一下感受，之前有对接过springcloud的项目，有以下几个感受 1.我们请求所有接口，都是请求同一个端口，路径不同，都会加一个token来验证权限 我感觉是这么实现的，服务器对外访问只开放gateway项目端口，然后加一个token来全局filter 当然，我不是这个项目的设计师，这是凭空想象而已。 简介This project provides an API Gateway built on top of the Spring Ecosystem, including: Spring 5, Spring Boot 2 and Project Reactor. Spring Cloud Gateway aims to provide a simple, yet effective way to route to APIs and provide cross cutting concerns to them such as: security, monitoring/metrics, and resiliency. 该项目提供了一个在spring生态系统上构建的api网关，包括spring 5,spring boot2和project reactor.spring cloud gateway旨在提供一个简单有效的路由到apis并且提供跨领域的关注点如：安全，检测、指标和弹性。 术语 Route: The basic building block of the gateway. It is defined by an ID, a destination URI, a collection of predicates, and a collection of filters. A route is matched if the aggregate predicate is true.—-Route是gateway中最基本块，如果所有predicate是true，那么route会被匹配 Predicate: This is a Java 8 Function Predicate. The input type is a Spring Framework ServerWebExchange. This lets you match on anything from the HTTP request, such as headers or parameters.通过java8提供的Predicate，我们可以匹配HttpRequest中的，headers或者parameters Filter: These are instances of Spring Framework GatewayFilter that have been constructed with a specific factory. Here, you can modify requests and responses before or after sending the downstream request.我们可以在发送给下游之前修改请求或者之后修改返回回来的响应。这里，我们用下面一张图来解释 ​ 从图中，我们需要注意到Filter中是支持请求前，和响应后的处理的 装配spring cloud gateway pom 1234567891011 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-gateway&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--暂时先注释 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;--&gt; &lt;!--spring cloud version :Hoxton.SR3--&gt; application.yml 123456789101112131415161718management: endpoints: web: exposure: include: \"*\"server: port: 10000#spring: 此处注释改为java注入# cloud:# gateway:# routes:# - id: first# uri: http://localhost:9000# predicates:# - Path=/**logging: level: org.springframework.cloud.gateway: debug java注入 1234567@Beanpublic RouteLocator customerRouteLocator(RouteLocatorBuilder builder)&#123; return builder.routes() .route(r-&gt;r.path(\"/**\") .uri(\"http://localhost:9000\").id(\"first\") ).build();&#125; 测试 12D:\\gitclonepackage\\cloud&gt;curl http:&#x2F;&#x2F;localhost:10000&#x2F;hello&#x2F;huskyui hello, huskyui Mon Apr 13 17:25:28 CST 2020 介绍predicate1234java8中的predicate,就是filter里面的函数。这是一个比较直观的例子List&lt;Integer&gt; list &#x3D; new ArrayList&lt;&gt;(Arrays.asList(1,2,3,4,5,6,7,8,9));list.stream().filter(t-&gt;t&lt;5).forEach(System.out::println);输出 1,2,3,4 PathRoutePredicateFactory1234567@Beanpublic RouteLocator customerRouteLocator(RouteLocatorBuilder builder)&#123; return builder.routes() .route(r-&gt;r.path(\"/**\") .uri(\"http://localhost:9000\").id(\"first\") ).build();&#125; 123放开了&#x2F;**,也就是放开了所有http:&#x2F;&#x2F;localhost:9000所有路径D:\\gitclonepackage\\cloud&gt;curl http:&#x2F;&#x2F;localhost:10000&#x2F;hello&#x2F;huskyuihello, huskyui Mon Apr 13 17:25:28 CST 2020 CookieRoutePredicateFactory12345678@Beanpublic RouteLocator customerRouteLocator(RouteLocatorBuilder builder)&#123; return builder.routes() .route(r-&gt;r .cookie(\"token\",\"kee.e\") .uri(\"http://localhost:9000\").id(\"first\") ).build();&#125; 123456D:\\gitclonepackage\\cloud&gt;curl http:&#x2F;&#x2F;localhost:10000&#x2F;hello&#x2F;huskyui&#123;&quot;timestamp&quot;:&quot;2020-04-13T10:03:43.548+0000&quot;,&quot;path&quot;:&quot;&#x2F;hello&#x2F;huskyui&quot;,&quot;status&quot;:404,&quot;error&quot;:&quot;Not Found&quot;,&quot;message&quot;:null,&quot;requestId&quot;:&quot;b330030a-1&quot;&#125;D:\\gitclonepackage\\cloud&gt;curl http:&#x2F;&#x2F;localhost:10000&#x2F;hello&#x2F;huskyui --cookie &quot;token&#x3D;keexe&quot;hello, huskyui Mon Apr 13 18:03:55 CST 2020D:\\gitclonepackage\\cloud&gt;curl http:&#x2F;&#x2F;localhost:10000&#x2F;hello&#x2F;huskyui --cookie &quot;token&#x3D;keeeee&quot;&#123;&quot;timestamp&quot;:&quot;2020-04-13T10:09:09.207+0000&quot;,&quot;path&quot;:&quot;&#x2F;hello&#x2F;huskyui&quot;,&quot;status&quot;:404,&quot;error&quot;:&quot;Not Found&quot;,&quot;message&quot;:null,&quot;requestId&quot;:&quot;23aba850-3&quot;&#125; 组合使用123456789101112@Beanpublic RouteLocator customerRouteLocator(RouteLocatorBuilder builder)&#123; return builder.routes() .route(r-&gt;r .method(HttpMethod.POST) .and() .path(\"/**\") .and() .cookie(\"token\",\"kee.e\") .uri(\"http://localhost:9000\").id(\"first\") ).build();&#125; 12D:\\gitclonepackage\\cloud&gt;curl -X POST http:&#x2F;&#x2F;localhost:10000&#x2F;hello&#x2F;huskyui --cookie &quot;token&#x3D;keeie&quot;hello, huskyui Mon Apr 13 18:13:54 CST 2020 自定义Predicate123456789101112131415161718192021222324252627282930313233343536373839404142// 我们先去看一下cookie判断的源码 CookieRoutePredicateFactory.java @Override public Predicate&lt;ServerWebExchange&gt; apply(Config config) &#123; return new GatewayPredicate() &#123; @Override public boolean test(ServerWebExchange exchange) &#123; List&lt;HttpCookie&gt; cookies = exchange.getRequest().getCookies() .get(config.name); if (cookies == null) &#123; return false; &#125; for (HttpCookie cookie : cookies) &#123; if (cookie.getValue().matches(config.regexp)) &#123; return true; &#125; &#125; return false; &#125; @Override public String toString() &#123; return String.format(\"Cookie: name=%s regexp=%s\", config.name, config.regexp); &#125; &#125;; &#125;// 很好理解的代码，我们写一串header判断的 @Bean public RouteLocator customerRouteLocator(RouteLocatorBuilder builder) &#123; return builder.routes() .route(r -&gt; r.predicate(t -&gt; &#123; List&lt;String&gt; values= t.getRequest().getHeaders().get(\"token\"); if(values==null || values.isEmpty())&#123; return false; &#125; return values.stream().anyMatch(value-&gt;value.equals(\"123456\")); &#125;) .uri(\"lb://eureka-consumer\").id(\"first\") ).build(); &#125; D:\\gitclonepackage\\cloud&gt;curl -X POST http://localhost:10000/hello/huskyui --header \"token: 123456\"hello, huskyui Thu Apr 16 14:58:20 CST 2020 介绍filterRoute filters allow the modification of the incoming HTTP request or outgoing HTTP response in some manner. Route filters are scoped to a particular route. Spring Cloud Gateway includes many built-in GatewayFilter Factories. 路由过滤器可以修改HTTP请求和HTTP响应，路由过滤器的作用域是特定的路由。spring cloud gateway有很多内置的网关过滤器的工厂。 使用PathRoutePredicateFactory和StripPrefixGatewayFilterFactory实现对特定项目访问123456789101112 @Bean public RouteLocator customerRouteLocator(RouteLocatorBuilder builder) &#123; return builder.routes() .route(r -&gt; r.path(\"/consumer/**\") .filters(f-&gt;f.stripPrefix(1)) .uri(\"lb://eureka-consumer\").id(\"first\") ).build(); &#125;D:\\gitclonepackage\\cloud&gt;curl -X POST http://localhost:10000/consumer/hello/huskyuihello, huskyui Thu Apr 16 15:16:31 CST 2020// 在访问的时候，由于stripPrefix是1，会去除/consumer这一层，真正的会转发成 // lb://eureka-consumer/hello/huskyui 修改RequestBody中信息12345678910111213141516171819202122232425 @Bean public RouteLocator customerRouteLocator(RouteLocatorBuilder builder) &#123; return builder.routes() .route(r -&gt; r.path(\"/producer/**\") .filters(f -&gt; f.stripPrefix(1) .modifyRequestBody(Map.class, Map.class, MediaType.APPLICATION_JSON_VALUE, (serverWebExchange, s) -&gt; &#123; System.out.println(s); s.put(\"name\",\"adios\"); return Mono.just(s); &#125;)) .uri(\"lb://eureka-producer\").id(\"first\") ).build(); &#125;// 可以看到这个s的类型是Map.class,我修改的对应name的值，POST http://localhost:10000/producer/helloContent-Type: application/json&#123;\"name\": \"huskyui\"&#125;hello, adios Thu Apr 16 18:34:56 CST 2020// 可以看到我修改对应的requestBody的值，在控制台也打印了初始RequestBody请求json（上面请求方式是通过idea里面内置的请求方式） 全局拦截器The GlobalFilter interface has the same signature as GatewayFilter. These are special filters that are conditionally applied to all routes. GlobalFilter接口具有与gatewayFilter相同的签名，这些是特殊过滤器，有条件地应用于所有路由。 后续从现在开始，暂停更新spring cloud gateway相关博客，我先去学点别的了。学习这种并没有什么用。 参考纯洁的微笑写的spring cloud文档windmt写的文档spring cloud gateway官方文档github上spring cloud gateway提供的samples","categories":[],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://yoursite.com/tags/SpringCloud/"},{"name":"Gateway","slug":"Gateway","permalink":"http://yoursite.com/tags/Gateway/"}]},{"title":"SpringCloud-config","slug":"SpringCloud-config","date":"2020-03-26T08:42:05.000Z","updated":"2020-03-30T07:55:24.609Z","comments":true,"path":"2020/03/26/SpringCloud-config/","link":"","permalink":"http://yoursite.com/2020/03/26/SpringCloud-config/","excerpt":"","text":"Spring Cloud Config简介Spring Cloud Config provides server-side and client-side support for externalized configuration in a distributed system. With the Config Server, you have a central place to manage external properties for applications across all environments. The concepts on both client and server map identically to the Spring Environment and PropertySource abstractions, so they fit very well with Spring applications but can be used with any application running in any language. As an application moves through the deployment pipeline from dev to test and into production, you can manage the configuration between those environments and be certain that applications have everything they need to run when they migrate. The default implementation of the server storage backend uses git, so it easily supports labelled versions of configuration environments as well as being accessible to a wide range of tooling for managing the content. It is easy to add alternative implementations and plug them in with Spring configuration. Spring Cloud Config为分布式系统中的外部化配置提供了服务器端和客户端支持。有了Config Server，您就有了一个中心位置来管理跨所有环境的应用程序的外部属性。客户机和服务器上的概念与Spring环境和PropertySource抽象完全相同，因此它们非常适合Spring应用程序，但可以用于以任何语言运行的任何应用程序.当应用程序通过部署管道从dev转移到测试并进入生产环境时，您可以在两者之间管理配置.服务器存储后端默认的实现使用git，因此它很容易支持配置环境的标记版本，并且可以访问各种各样的工具来管理内容。很容易添加替代实现并将它们插入Spring配置中 config-server创建一个配置仓库 具体样式，可以看https://github.com/huskyui/config-repo 在spring-cloud下面有三个文件，config-dev.yml和config-prod.yml和config-test.yml 导入pom 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;!--spring-cloud.version Hoxton.SR3 --&gt; application.yml 12345678910111213141516spring: application: name: config-server cloud: config: server: git: uri: https://github.com/huskyui/config-repo # uri search-paths: spring-cloud # 层级server: port: 12000eureka: client: service-url: defaultZone: http://localhost:7000/eureka/# 今天写defalutZone写错了，发现应用在请求loclahost:8761/eureka/,原来默认值是这个 @EnableConfigServer 12345678910@SpringBootApplication@EnableConfigServer// 开启config-serverpublic class CloudConfigServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(CloudConfigServerApplication.class, args); &#125;&#125; 测试 123curl http:&#x2F;&#x2F;localhost:12000&#x2F;config-dev.ymlcurrency: name: huskyui-update-2020-03-24-----2 config-clientpom 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-config&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt;&lt;!--spring-cloud-version Hoxton.SR3--&gt; bootstrap.yml bootstrap.yml优先于application.yml配置 12345678910111213spring: cloud: config: label: master # 用于拉取远程配置属性的标签名称，在基于git的服务器，通常是master name: config # Name of application used to fetch remote properties. 对应config-dev.yml中的config profile: dev # The default profile to use when fetching remote configuration discovery: enabled: true #Flag to indicate that config server discovery is enabled service-id: config-server #Service id to locate config server.也就是config-server注册在eureka中的application-nameeureka: client: service-url: defaultZone: http://localhost:7000/eureka/ application.yml 12345678910spring: application: name: config-git server: port: 13000management: endpoints: web: exposure: include: refresh # 放开/actuator/refresh路径，具体是什么样式的请求，还得看文档 HelloController 1234567891011121314151617181920@RestController/** * Convenience annotation to put a &lt;code&gt;@Bean&lt;/code&gt; definition in * &#123;@link org.springframework.cloud.context.scope.refresh.RefreshScope refresh scope&#125;. * Beans annotated this way can be refreshed at runtime and any components that are using * them will get a new instance on the next method call, fully initialized and injected * with all dependencies. 在调用/actuator/refresh时，运行期间，这个bean会被刷新*/@RefreshScopepublic class HelloController &#123; @Value(\"$&#123;currency.name:error&#125;\") private String name; @RequestMapping(\"/hello\") public String name()&#123; return name; &#125;&#125; 测试 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849501.测试单个应用刷新打包运行测试当前数据问题curl localhost:13000&#x2F;hellohuskyui-update-2020-03-24-----2更新数据更新数据config-dev里面的数据currency: name: huskyui-update-2020-03-27 并提交到远程仓库调用刷新接口curl -X POST localhost:13000&#x2F;actuator&#x2F;refresh[&quot;currency.name&quot;,&quot;config.client.version&quot;]curl localhost:13000&#x2F;hellohuskyui-update-2020-03-27可以看到数据刷新成功2.测试多个应用刷新java -jar xxx.jar --server.port&#x3D;13000java -jar xxx.jar --server.port&#x3D;13001curl localhost:13000&#x2F;hellohuskyui-update-2020-03-27curl localhost:13001&#x2F;hellohuskyui-update-2020-03-27更新数据config-dev.ymlcurrency: name: huskyui-update-2020-03-27-for-two-client-test2并提交到远程仓库curl localhost:13000&#x2F;hellohuskyui-update-2020-03-27curl localhost:13001&#x2F;hellohuskyui-update-2020-03-27下面执行刷新操作curl -X POST localhost:13000&#x2F;actuator&#x2F;refresh[&quot;currency.name&quot;,&quot;config.client.version&quot;]curl localhost:12000&#x2F;config-dev.ymlcurrency: name: huskyui-update-2020-03-27-for-two-client-test2curl localhost:13000&#x2F;hellohuskyui-update-2020-03-27-for-two-client-test2curl localhost:13001&#x2F;hellohuskyui-update-2020-03-27curl -X POST localhost:13001&#x2F;actuator&#x2F;refresh[&quot;currency.name&quot;,&quot;config.client.version&quot;]curl -X POST localhost:13001&#x2F;hellohuskyui-update-2020-03-27-for-two-client-test2可以看到，如果配置文件更新时，&#x2F;actuator&#x2F;refresh只是针对单个应用的，如果需要更新所有应用需要分别是去刷新对应的应用 使用spring-cloud-bus实现群体刷新 从上面的架构图，我们config-server和config-client都订阅一下RabbitMQ 我们需要修改原来的config-server POM 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-bus&lt;/artifactId&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-stream-binder-rabbit&lt;/artifactId&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt; application.yml添加 1234567891011spring: rabbitmq: host: localhost port: 5672 username: guest password: guest ## 上述是RabbitMQ相关连接参数，漏了一个vhostmanagement: endpoints: web: exposure: include: \"*\" ## 放开/actuator/bus-refresh config-client修改部分也和上述一样 修改后，启动config-server,并启动两台config-client,端口不同（–server.port=different_port） 我们访问http://localhost:15672/访问RabbitMQ客户端，点击exchange,可以看到是 springCloudBus,是topic类型,三个绑定该exchange的queue的routing key都是#，也就是不处理fanout 测试 123456789101112131415首先修改config-repo,并提交首先查看数据D:\\gitclonepackage\\cloud&gt;curl localhost:13000&#x2F;hellohuskyui-update-2020-03-30D:\\gitclonepackage\\cloud&gt;curl localhost:13001&#x2F;hellohuskyui-update-2020-03-30调用刷新操作curl -X POST localhost:12000&#x2F;actuator&#x2F;bus-refresh这个请求的时候，是请求config-server;当然也可以请求config-client的bus-refreshD:\\gitclonepackage\\cloud&gt;curl localhost:13001&#x2F;hellohuskyui-update-2020-03-30-last-commitD:\\gitclonepackage\\cloud&gt;curl localhost:13000&#x2F;hellohuskyui-update-2020-03-30-last-commit 本篇文章参考： Spring Cloud（七）：配置中心（Git 版与动态刷新）Spring Cloud（八）：配置中心（服务化与高可用） Spring Cloud（九）：配置中心（消息总线）【Finchley 版】","categories":[{"name":"springcloud","slug":"springcloud","permalink":"http://yoursite.com/categories/springcloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://yoursite.com/tags/SpringCloud/"},{"name":"Eureka","slug":"Eureka","permalink":"http://yoursite.com/tags/Eureka/"}]},{"title":"SpringCloud-Hystrix","slug":"SpringCloud-Hystrix","date":"2020-03-23T10:09:49.000Z","updated":"2020-03-24T07:20:07.545Z","comments":true,"path":"2020/03/23/SpringCloud-Hystrix/","link":"","permalink":"http://yoursite.com/2020/03/23/SpringCloud-Hystrix/","excerpt":"","text":"HystrixHystrix is a latency and fault tolerance library designed to isolate points of access to remote systems, services and 3rd party libraries, stop cascading failure and enable resilience in complex distributed systems where failure is inevitable. Hystrix是一个延迟和容错库，旨在隔离远程系统、服务和第三方库的访问点，停止次级故障，并且不可避免的复杂分布式系统中实现自我恢复能力。 配置hystrixpom 123456789101112131415161718192021222324252627282930 &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.67&lt;/version&gt; &lt;/dependency&gt;&lt;!--web--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--Eureka client --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- Hystrix --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- 声明性REST客户端，使用注解修饰接口，动态实现 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!--为了后续放开hystrix.stream路径--&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt; &lt;/dependency&gt; application.yml 12345678910111213141516171819202122spring: application: name: eureka-consumer-feign-hystrix# 当前应用名称eureka: client: service-url: defaultZone: http://localhost:7000/eureka/ # 映射到Eureka server的路径server: port: 9001feign: hystrix: enabled: true# an OpenFeign client will be wrapped with a Hystrix circuit breaker# 一个OpenFeign客户端将包装有Hystrix断路器management: endpoints: web: exposure: include: hystrix.stream# 为了给Hystrix Dashboard提供使用 启动类配置 1234567891011@EnableFeignClients//扫描包下被@FeignClient注解的，需要和@Configuration同时使用@EnableHystrix//开启断路器，并且自动配置找到Hystrix类（if they are available）@SpringBootApplicationpublic class CloudConsumerFeignHystrixApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(CloudConsumerFeignHystrixApplication.class, args); &#125;&#125; 远程调用 1234567891011@Component// name： the service id with optional protocol prefix.带有可选协议前缀的服务ID// fallback： 指定的Feign客户端接口的后备类。fallback类必须实现该接口并且是一个有效的spring bean//Fallback class for the specified Feign client interface. The fallback class must// implement the interface annotated by this annotation and be a valid spring bean.@FeignClient(name = \"eureka-producer\",fallback = HelloRemoteHystrix.class)public interface HelloRemote &#123; @RequestMapping(\"/hello\") String hello(@RequestBody JSONObject requestJSON);&#125; fallback类 1234567@Componentpublic class HelloRemoteHystrix implements HelloRemote &#123; @Override public String hello(JSONObject requestJSON) &#123; return \"hello world\"; &#125;&#125; controller 1234567891011121314@RestControllerpublic class HelloController &#123; @Resource private HelloRemote helloRemote; @RequestMapping(\"/hello/&#123;name&#125;\") public String hello(@PathVariable(name = \"name\")String name)&#123; JSONObject requestJSON = new JSONObject(); requestJSON.put(\"name\",name); return helloRemote.hello(requestJSON); &#125;&#125; 测试 12345678910将eureka-server，producer，feign-hystrix三个项目启动，在eureka-server上可以看到producer和feign-hystrix都已经注册成功。访问：localhost:9001&#x2F;hello&#x2F;huskyuihello, huskyui Tue Mar 24 14:34:44 CST 2020将producer关闭访问：localhost:9001&#x2F;hello&#x2F;huskyuihello world再次将producer启动hello, huskyui Tue Mar 24 14:40:27 CST 2020这边，可以看到熔断能力，以及自我恢复能力 配置一个Hystrix dashboardpom 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix-dashboard&lt;/artifactId&gt;&lt;/dependency&gt; application.yml 12345spring: application: name: hystrix-dashboardserver: port: 11000 添加注解@EnableHystrixDashboard 123456789@SpringBootApplication@EnableHystrixDashboardpublic class CloudHystrixDashboardApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(CloudHystrixDashboardApplication.class, args); &#125;&#125; 测试 12345运行该项目访问： http:&#x2F;&#x2F;localhost:11000&#x2F;hystrix在启动后输入http:&#x2F;&#x2F;localhost:9001&#x2F;actuator&#x2F;hystrix.stream9001是feign-hystrix的项目的端口，当时我们引入了actuator，开放hystrix.stream可以看到dashboard相关","categories":[{"name":"springcloud","slug":"springcloud","permalink":"http://yoursite.com/categories/springcloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://yoursite.com/tags/SpringCloud/"},{"name":"Hystrix","slug":"Hystrix","permalink":"http://yoursite.com/tags/Hystrix/"}]},{"title":"SpringCloud-Eureka","slug":"SpringCloud-Eureka","date":"2020-03-20T03:09:02.000Z","updated":"2020-03-20T08:42:54.373Z","comments":true,"path":"2020/03/20/SpringCloud-Eureka/","link":"","permalink":"http://yoursite.com/2020/03/20/SpringCloud-Eureka/","excerpt":"","text":"Eureka简介Eureka是一种基于REST(Representational State Thransfer表现层状态转移)的服务，主要用于AWS的定位服务，以便实现中间层服务器的负载均衡和故障转移。 单个注册中心整合pom配置1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; application.yml12345678910111213spring: application: name: eureka-serverserver: port: 7000 # Server HTTP port.eureka: instance: hostname: localhost # eureka实例的hostname client: register-with-eureka: false # 指示当前实例是否应在eureka服务器上注册其信息以供发现 fetch-registry: false # 指示当前实例是否从eureka服务器获取注册表信息 service-url: # 映射map。映射关于eureka服务器的url列表，map的value值可以是单个url，也可以是以,分割符分割的多个url，修改之后生效时间将在下一个循环中，由eurekaServiceUrlPollIntervalSeconds指定 defaultZone: http://$&#123;eureka.instance.hostname&#125;:$&#123;server.port&#125;/eureka/ 注解@EnableEurekaServer123456789@EnableEurekaServer // Annotation to activate Eureka Server related configuration. 激活eureka相关配置的注解@SpringBootApplicationpublic class EurekaServerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServerApplication.class, args); &#125;&#125; 打包部署运行123456mvn clean package -Dmaven.test.skip&#x3D;truejava -jar xxx.jar访问 localhost:7000 注册两个注册中心修改application.yaml配置文件123456789101112131415161718192021222324252627282930## 新增两个配置文件## application-peer1.ymlspring: application: name: eureka-serverserver: port: 7001 # Server HTTP port.eureka: instance: hostname: localhost # eureka实例的hostname client: register-with-eureka: true # 指示当前实例是否应在eureka服务器上注册其信息以供发现 fetch-registry: true # 指示当前实例是否从eureka服务器获取注册表信息 service-url: # 映射map。映射关于eureka服务器的url列表，map的value值可以是单个url，也可以是以,分割符分割的多个url，修改之后生效时间将在下一个循环中，由eurekaServiceUrlPollIntervalSeconds指定 defaultZone: http://127.0.0.1:7002/eureka/ ## application-peer2.yml spring: application: name: eureka-serverserver: port: 7002 # Server HTTP port.eureka: instance: hostname: localhost # eureka实例的hostname client: register-with-eureka: true # 指示当前实例是否应在eureka服务器上注册其信息以供发现 fetch-registry: true # 指示当前实例是否从eureka服务器获取注册表信息 service-url: # 映射map。映射关于eureka服务器的url列表，map的value值可以是单个url，也可以是以,分割符分割的多个url，修改之后生效时间将在下一个循环中，由eurekaServiceUrlPollIntervalSeconds指定 defaultZone: http://127.0.0.1:7001/eureka/ 打包部署12345678&#x2F;&#x2F; 打包mvn clean package -Dmaven.test.skip&#x3D;true&#x2F;&#x2F; 运行java -jar xxx.jar --spring.profiles.active&#x3D;peer1java -jar xxx.jpg --spring.profiles.active&#x3D;peer2&#x2F;&#x2F; 访问localhost:7001localhost:7002 服务提供和调用生成者pom12345678910111213141516&lt;!-- https://mvnrepository.com/artifact/com.alibaba/fastjson --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.67&lt;/version&gt;&lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; application.yml123456789spring: application: name: eureka-producereureka: client: service-url: defaultZone: http://127.0.0.1:7000/eureka/server: port: 8000 具体方法12345678@RestControllerpublic class HelloController &#123; @RequestMapping(\"/hello\") public String hello(@RequestBody JSONObject requestJSON) &#123; String name = requestJSON.getString(\"name\"); return \"hello, \" + name + \" \" + new Date(); &#125;&#125; 打包部署测试1234mvn clean package -Dmaven.test.skip&#x3D;truejava -jar xxx.jarcurl -H&#39;Content-Type: application&#x2F;json&#39; -d&#39;&#123;&quot;name&quot;:&quot;huskyui&quot;&#125;&#39; localhost:8000&#x2F;hellohello, huskyui Fri Mar 20 16:06:40 CST 2020 消费者pom123456789101112131415161718&lt;!-- https://mvnrepository.com/artifact/com.alibaba/fastjson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;1.2.67&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt; &lt;/dependency&gt; application.yml123456789spring: application: name: eureka-consumereureka: client: service-url: defaultZone: http://localhost:7000/eureka/server: port: 9000 添加@EnableFeignClients123456789@EnableFeignClients@SpringBootApplicationpublic class CloudEurekaConsumerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(CloudEurekaConsumerApplication.class, args); &#125;&#125; 具体代码12345678910111213141516171819@FeignClient(name = \"eureka-producer\")public interface HelloRemote &#123; @RequestMapping(\"/hello\") String hello(@RequestBody JSONObject requestJSON);&#125;@RestControllerpublic class HelloController &#123; @Autowired private HelloRemote helloRemote; @RequestMapping(\"/hello/&#123;name&#125;\") public String index(@PathVariable(\"name\")String name)&#123; JSONObject requestJSon = new JSONObject(); requestJSon.put(\"name\",name); return helloRemote.hello(requestJSon); &#125;&#125; 打包部署测试1234mvn clean package -Dmaven.test.skip&#x3D;truejava -jar xxx.jarcurl localhost:9000&#x2F;hello&#x2F;huskyuihello, huskyui Fri Mar 20 16:11:59 CST 2020 负载均衡启动两个不同端口的生产者，启动一个消费者会实现相关效果","categories":[{"name":"springcloud","slug":"springcloud","permalink":"http://yoursite.com/categories/springcloud/"}],"tags":[{"name":"SpringCloud","slug":"SpringCloud","permalink":"http://yoursite.com/tags/SpringCloud/"},{"name":"Eureka","slug":"Eureka","permalink":"http://yoursite.com/tags/Eureka/"}]},{"title":"SpringBoot整合RabbitMQ","slug":"SpringBoot整合RabbitMQ","date":"2020-03-19T02:25:44.000Z","updated":"2020-03-19T06:09:24.991Z","comments":true,"path":"2020/03/19/SpringBoot整合RabbitMQ/","link":"","permalink":"http://yoursite.com/2020/03/19/SpringBoot%E6%95%B4%E5%90%88RabbitMQ/","excerpt":"","text":"SpringBoot配置RabbitMQ配置maven1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt;&lt;/dependency&gt; 配置文件application.yml1234567spring: rabbitmq: username: user_mmr #用户名 password: 123 #密码 host: localhost # 你要连接的RabbitMQ的host port: 5672 # Rabbit的port virtual-host: '/vhost_mmr' #virtual-host RabbitMQ教程以下教程都可以在RabbitMQ在github的仓库rabbitmq-tutorial中找到，具体springboot在spring-amqp模块中。在这里面要讲一下如何运行相关代码 1234567891011121314151617181920212223### 打包项目mvn clean package### 运行项目java -jar xxx.jar --spring.profiles.active&#x3D;tut1,sender### 下面放上相关运行命令System.out.println(&quot;java -jar rabbit-tutorials.jar --spring.profiles.active&#x3D;hello-world,receiver&quot;);System.out.println(&quot;java -jar rabbit-tutorials.jar --spring.profiles.active&#x3D;hello-world,sender&quot;);System.out.println(&quot;java -jar rabbit-tutorials.jar --spring.profiles.active&#x3D;work-queues,receiver&quot;);System.out.println(&quot;java -jar rabbit-tutorials.jar --spring.profiles.active&#x3D;work-queues,sender&quot;);System.out.println(&quot;java -jar rabbit-tutorials.jar --spring.profiles.active&#x3D;pub-sub,receiver&quot;);System.out.println(&quot;java -jar rabbit-tutorials.jar --spring.profiles.active&#x3D;pub-sub,sender&quot;);System.out.println(&quot;java -jar rabbit-tutorials.jar --spring.profiles.active&#x3D;routing,receiver&quot;);System.out.println(&quot;java -jar rabbit-tutorials.jar --spring.profiles.active&#x3D;routing,sender&quot;);System.out.println(&quot;java -jar rabbit-tutorials.jar --spring.profiles.active&#x3D;topics,receiver&quot;);System.out.println(&quot;java -jar rabbit-tutorials.jar --spring.profiles.active&#x3D;topics,sender&quot;);#### 注意，该项目使用了定时任务你需要配置允许定时调度的注解@EnableScheduling helloworld123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354@Profile(&#123;\"tut1\",\"hello-world\"&#125;)@Configurationpublic class Tut1Config &#123; @Bean public Queue hello()&#123; return new Queue(\"hello\"); &#125; @Profile(\"receiver\") @Bean public Tut1Receiver receiver()&#123; return new Tut1Receiver(); &#125; @Profile(\"sender\") @Bean public Tut1Sender sender()&#123; return new Tut1Sender(); &#125;&#125;// 监听hello队列 Annotation that marks a method to be the target of a Rabbit message listener on the// specified queues()或者bindings(). @RabbitListener(queues = \"hello\")public class Tut1Receiver &#123; private static final Logger logger = LoggerFactory.getLogger(Tut1Receiver.class); // Annotation that marks a method to be the target of a Rabbit message // listener within a class that is annotated with &#123;@link RabbitListener&#125; @RabbitHandler public void receive(String in) &#123; logger.info(\"[x] Received:&#123;&#125; \", in); System.out.println(\"[x] Received:&#123;&#125; \"+ in); &#125;&#125;public class Tut1Sender &#123; private final static Logger logger = LoggerFactory.getLogger(Tut1Sender.class); @Autowired private RabbitTemplate rabbitTemplate; @Autowired private Queue queue; @Scheduled(fixedDelay = 1000, initialDelay = 500) public void send() &#123; String msg = \"hello world\"; this.rabbitTemplate.convertAndSend(queue.getName(), msg); logger.info(\"[x] sent :\" + msg); System.out.println(\"[x] sent :\" + msg); &#125;&#125;// java -jar xxx.jar --spring.profiles.active=hello-world,receiver// java -jar xxx.jar --spring.profiles.active=hello-world,sender work-queues12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485@RabbitListener(queues = \"tut.hello\")public class Tut2Receiver &#123; private final static Logger logger = LoggerFactory.getLogger(Tut2Receiver.class); private final int instance; public Tut2Receiver(int i)&#123; this.instance = i; &#125; @RabbitHandler public void receive(String in) throws InterruptedException&#123; StopWatch watch = new StopWatch(); watch.start(); logger.info(\"instance \" + this.instance+\"[x] recived\" + in); doWork(in); watch.stop(); logger.info(\"instance \" + this.instance +\"[x] done\"); &#125; private void doWork(String in) throws InterruptedException&#123; for (char ch:in.toCharArray())&#123; if(ch == '.')&#123; TimeUnit.SECONDS.sleep(1); &#125; &#125; &#125;&#125;public class Tut2Sender &#123; private static Logger logger = LoggerFactory.getLogger(Tut2Sender.class); @Autowired private RabbitTemplate rabbitTemplate; @Autowired private Queue queue; AtomicInteger dots = new AtomicInteger(0); AtomicInteger count = new AtomicInteger(0); @Scheduled(fixedDelay = 1000,initialDelay = 500) public void send()&#123; StringBuilder builder = new StringBuilder(\"hello\"); if(dots.getAndIncrement() == 3)&#123; dots.set(1); &#125; for(int i = 0;i&lt;dots.get();i++)&#123; builder.append(\".\"); &#125; builder.append(count.incrementAndGet()); String msg = builder.toString(); rabbitTemplate.convertAndSend(queue.getName(),msg); logger.info(\"[x] sent &#123;&#125;\",msg); &#125;&#125;@Profile(&#123;\"tut2\",\"work-queues\"&#125;)@Configurationpublic class Tut2Config &#123; @Bean public Queue hello()&#123; return new Queue(\"tut.hello\"); &#125; @Profile(\"receiver\") private static class ReceiverConfig&#123; @Bean public Tut2Receiver receiver1()&#123; return new Tut2Receiver(1); &#125; @Bean public Tut2Receiver receiver2()&#123; return new Tut2Receiver(2); &#125; &#125; @Profile(\"sender\") @Bean public Tut2Sender sender()&#123; return new Tut2Sender(); &#125;&#125; pub-sub123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103@Configuration@Profile(&#123;\"tut3\",\"pub-sub\",\"publish-subscribe\"&#125;)public class Tut3Config &#123; @Bean public FanoutExchange fanout()&#123; return new FanoutExchange(\"tut.fanout\"); &#125; @Profile(\"receiver\") private static class ReceiverConfig&#123; @Bean public Queue autoDeleteQueue1()&#123; return new AnonymousQueue(); &#125; @Bean public Queue autoDeleteQueue2()&#123; return new AnonymousQueue(); &#125; // 这个地方可能注册不成功 @Bean public Binding binding1(FanoutExchange fanout,Queue autoDeleteQueue1)&#123; return BindingBuilder.bind(autoDeleteQueue1).to(fanout); &#125; @Bean public Binding binding2(FanoutExchange fanout,Queue autoDeleteQueue2)&#123; return BindingBuilder.bind(autoDeleteQueue2).to(fanout); &#125; @Bean public Tut3Receiver receiver()&#123; return new Tut3Receiver(); &#125; &#125; @Profile(\"sender\") @Bean public Tut3Sender sender()&#123; return new Tut3Sender(); &#125;&#125;public class Tut3Receiver &#123; @RabbitListener(queues = \"#&#123;autoDeleteQueue1.name&#125;\") public void receive1(String in) throws InterruptedException&#123; receive(in,1); &#125; @RabbitListener(queues = \"#&#123;autoDeleteQueue2.name&#125;\") public void receive2(String in) throws InterruptedException&#123; receive(in,2); &#125; public void receive(String in,int receiver) throws InterruptedException&#123; StopWatch watch = new StopWatch(); watch.start(); System.out.println(\"instance \" + receiver + \"[x] Received\" + in); doWork(in); watch.stop(); System.out.println(\"instance\" + receiver + \"[x] Done in\" + watch.getTotalTimeSeconds()+\"s\"); &#125; private void doWork(String in) throws InterruptedException&#123; for(char ch: in.toCharArray())&#123; if(ch == '.')&#123; TimeUnit.SECONDS.sleep(1); &#125; &#125; &#125;&#125;public class Tut3Sender &#123; @Autowired private RabbitTemplate rabbitTemplate; @Autowired private FanoutExchange fanout; AtomicInteger dots = new AtomicInteger(0); AtomicInteger count = new AtomicInteger(0); @Scheduled(fixedDelay = 1000,initialDelay = 500) public void send()&#123; StringBuilder builder = new StringBuilder(\"hello\"); if(dots.getAndIncrement() == 3)&#123; dots.set(1); &#125; for(int i = 0;i &lt; dots.get();i++)&#123; builder.append(\".\"); &#125; builder.append(count.incrementAndGet()); String message = builder.toString(); rabbitTemplate.convertAndSend(fanout.getName(),\"\",message); System.out.println(\"[x] sent\" +message); &#125;&#125; direct123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115@Profile(&#123;\"tut4\",\"routing\"&#125;)@Configurationpublic class Tut4Config &#123; // 设置exchange @Bean public DirectExchange direct()&#123; return new DirectExchange(\"tut.direct\"); &#125; @Profile(\"receiver\") private static class ReceiverConfig&#123; // 创建两个匿名Queue an anonymous, non-durable, exclusive, auto-delete queue @Bean public Queue autoDeleteQueue1()&#123; return new AnonymousQueue(); &#125; @Bean public Queue autoDeleteQueue2()&#123; return new AnonymousQueue(); &#125; // 绑定相关数据 @Bean public Binding binding1a(DirectExchange directExchange,Queue autoDeleteQueue1)&#123; return BindingBuilder.bind(autoDeleteQueue1).to(directExchange).with(\"orange\"); &#125; @Bean public Binding binding1b(DirectExchange directExchange,Queue autoDeleteQueue1)&#123; return BindingBuilder.bind(autoDeleteQueue1).to(directExchange).with(\"black\"); &#125; @Bean public Binding binding2a(DirectExchange directExchange,Queue autoDeleteQueue2)&#123; return BindingBuilder.bind(autoDeleteQueue2).to(directExchange).with(\"green\"); &#125; @Bean public Binding binding2b(DirectExchange direct,Queue autoDeleteQueue2)&#123; return BindingBuilder.bind(autoDeleteQueue2).to(direct).with(\"black\"); &#125; // @Bean public Tut4Receiver receiver()&#123; return new Tut4Receiver(); &#125; &#125; @Profile(\"sender\") @Bean public Tut4Sender sender()&#123; return new Tut4Sender(); &#125; &#125;public class Tut4Receiver &#123; @RabbitListener(queues = \"#&#123;autoDeleteQueue1.name&#125;\") public void receive1(String in) throws InterruptedException&#123; receive(in,1); &#125; @RabbitListener(queues = \"#&#123;autoDeleteQueue2.name&#125;\") public void receive2(String in) throws InterruptedException&#123; receive(in,2); &#125; public void receive(String in,int receiver) throws InterruptedException&#123; StopWatch watch = new StopWatch(); watch.start(); System.out.println(\"instance \" + receiver+\"[x] received ' \" + in+ \"'\"); doWork(in); watch.stop(); System.out.println(\"instance \"+ receiver+\"[x] Done in\" + watch.getTotalTimeSeconds()+\"s\"); &#125; private void doWork(String in) throws InterruptedException&#123; for(char ch: in.toCharArray())&#123; if(ch == '.')&#123; TimeUnit.SECONDS.sleep(1); &#125; &#125; &#125;&#125;public class Tut4Sender &#123; @Autowired private RabbitTemplate rabbitTemplate; @Autowired private DirectExchange directExchange; AtomicInteger index = new AtomicInteger(0); AtomicInteger count = new AtomicInteger(0); private final String[] keys = &#123;\"orange\", \"black\", \"green\"&#125;; @Scheduled(fixedDelay = 1000, initialDelay = 500) public void send() &#123; StringBuilder builder = new StringBuilder(\"Hello to \"); if (this.index.incrementAndGet() == 3) &#123; this.index.set(0); &#125; String key = keys[this.index.get()]; builder.append(key).append(' '); builder.append(this.count.incrementAndGet()); String message = builder.toString(); rabbitTemplate.convertAndSend(directExchange.getName(), key, message); System.out.println(\"[X] sent '\" + message + \"'\"); &#125;&#125; topic123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109@Profile(&#123;\"tut5\",\"topics\"&#125;)@Configurationpublic class Tut5Config &#123; @Bean public TopicExchange topicExchange()&#123; return new TopicExchange(\"tut.topic\"); &#125; @Profile(\"receiver\") private static class ReceiverConfig&#123; @Bean public Tut5Receiver receiver()&#123; return new Tut5Receiver(); &#125; @Bean public Queue autoDeleteQueue1()&#123; return new AnonymousQueue(); &#125; @Bean public Queue autoDeleteQueue2()&#123; return new AnonymousQueue(); &#125; @Bean public Binding binding1a(TopicExchange topicExchange,Queue autoDeleteQueue1)&#123; return BindingBuilder.bind(autoDeleteQueue1).to(topicExchange).with(\"*.orange.*\"); &#125; @Bean public Binding binding1b(TopicExchange topicExchange,Queue autoDeleteQueue1)&#123; return BindingBuilder.bind(autoDeleteQueue1).to(topicExchange).with(\"*.*.rabbit\"); &#125; @Bean public Binding binding2a(TopicExchange topic,Queue autoDeleteQueue2)&#123; return BindingBuilder.bind(autoDeleteQueue2).to(topic).with(\"lazy.#\"); &#125; &#125; @Profile(\"sender\") @Bean public Tut5Sender sender()&#123; return new Tut5Sender(); &#125;&#125;public class Tut5Receiver &#123; @RabbitListener(queues = \"#&#123;autoDeleteQueue1.name&#125;\") public void receive1(String in) throws InterruptedException &#123; receive(in, 1); &#125; @RabbitListener(queues = \"#&#123;autoDeleteQueue2.name&#125;\") public void receive2(String in) throws InterruptedException &#123; receive(in, 2); &#125; public void receive(String in, int receiver) throws InterruptedException &#123; StopWatch watch = new StopWatch(); watch.start(); System.out.println(\"instance \" + receiver + \" [X] received ' \" + in + \" '\"); doWork(in); watch.stop(); System.out.println(\"instance \" + receiver + \" [X] Done in\" + watch.getTotalTimeSeconds() +\"s\"); &#125; private void doWork(String in) throws InterruptedException&#123; for(char ch : in.toCharArray())&#123; if(ch == '.')&#123; TimeUnit.SECONDS.sleep(1); &#125; &#125; &#125;&#125;public class Tut5Sender &#123; @Autowired private RabbitTemplate rabbitTemplate; @Autowired private TopicExchange topicExchange; AtomicInteger index = new AtomicInteger(0); AtomicInteger count = new AtomicInteger(0); private final String[] keys = &#123;\"quick.orange.rabbit\", \"lazy.orange.elephant\", \"quick.orange.fox\", \"lazy.brown.fox\", \"lazy.pink.rabbit\", \"quick.brown.fox\"&#125;; @Scheduled(fixedDelay = 1000,initialDelay = 500) public void send()&#123; StringBuilder builder = new StringBuilder(\"Hello to \"); if(this.index.incrementAndGet() == keys.length)&#123; this.index.set(0); &#125; String key = keys[this.index.get()]; builder.append(key).append(\" \"); builder.append(this.count.incrementAndGet()); String message = builder.toString(); rabbitTemplate.convertAndSend(topicExchange.getName(),key,message); &#125;&#125;","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/categories/rabbitmq/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ-topic","slug":"RabbitMQ-topic","date":"2020-03-13T02:35:52.000Z","updated":"2020-03-13T05:53:59.511Z","comments":true,"path":"2020/03/13/RabbitMQ-topic/","link":"","permalink":"http://yoursite.com/2020/03/13/RabbitMQ-topic/","excerpt":"","text":"Topic在之前的一篇教程中，我们改进了日志系统。我们使用direct直接广播，而不是使用fanout,从而获得了选择性接收日志的可能性。 虽然使用direct exchange改进了我们的系统，但它任然有局限性–它不能基于多个标准进行路由。 Topic exchange消息发送到topic exchange不能是一个随意的routing-key。它必须是一个由.分割单纯列表。 例如stock.usd.nyse、nyse.vmw、quick.orange.rabbit等。routing-key可以有尽可能多，但是最多255字节。 绑定键必须采用相同的形式。topic exchange和direct exchange类似-使用特定routig key发送的消息会被传递到匹配binding key的队列里面。但是，对于routing key有两个特殊情况 * (star）可以替代一个单词 `#``(hash) 可以代替0个或多个单词 Topic exchangeTopic exchange是非常厉害的并且可以表现和其他exchange一样的 当一个队列是用#绑定，那么就会接受到所有信息，不管routing-key是什么，就像fanout 当绑定中不使用*和#等特殊字符，topic exchange就会像direct exchange Sender.java12345678910111213141516171819public class Send &#123; private final static String EXCHANGE_NAME = \"test_exchange_topic\"; public static void main(String[] args) throws IOException, TimeoutException &#123; // 创建连接 Connection connection = ConnectionUtils.getConnection(); Channel channel = connection.createChannel(); //声明exchange channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.TOPIC); // 消息内容 String msg = \"hello world!\"; channel.basicPublish(EXCHANGE_NAME,\"routekey1.1\",null,msg.getBytes()); channel.close(); connection.close(); &#125;&#125; rece1.java12345678910111213141516171819202122232425262728293031323334353637public class Rece1 &#123; private final static String EXCHANGE_NAME = \"test_exchange_topic\"; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection = ConnectionUtils.getConnection(); Channel channel = connection.createChannel(); // String queueName = channel.queueDeclare().getQueue();// // 声明队列// channel.queueDeclare(queueName,false,false,false,null); //绑定队列到交换机上 channel.queueBind(queueName,EXCHANGE_NAME,\"routekey.*\"); //同一时刻服务器只发送一条消息 channel.basicQos(1); Consumer consumer = new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body,\"utf-8\"); System.out.println(\"rece1 :\" + msg); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; System.out.println(\"rece1 done\"); channel.basicAck(envelope.getDeliveryTag(),false); &#125; &#125; &#125;; channel.basicConsume(queueName,false,consumer); &#125;&#125; rece2.java1234567891011121314151617181920212223242526272829303132333435public class Rece2 &#123; private final static String QUEUE_NAME = \"test_queue_topic_work_2\"; private final static String EXCHANGE_NAME = \"test_exchange_topic\"; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection = ConnectionUtils.getConnection(); Channel channel = connection.createChannel(); // 声明队列 channel.queueDeclare(QUEUE_NAME,false,false,false,null); //绑定队列到交换机上 channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,\"*.*\"); //同一时刻服务器只发送一条消息 channel.basicQos(1); Consumer consumer = new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body,\"utf-8\"); System.out.println(\"rece1 :\" + msg); try &#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; System.out.println(\"rece1 done\"); channel.basicAck(envelope.getDeliveryTag(),false); &#125; &#125; &#125;; channel.basicConsume(QUEUE_NAME,false,consumer); &#125;&#125;","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/categories/rabbitmq/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ-routing","slug":"RabbitMQ-routing","date":"2020-03-09T10:42:59.000Z","updated":"2020-03-11T06:44:48.784Z","comments":true,"path":"2020/03/09/RabbitMQ-routing/","link":"","permalink":"http://yoursite.com/2020/03/09/RabbitMQ-routing/","excerpt":"","text":"routing在之前的导航中，我们创建了一个简单日志系统，我们能够将日志信息广播到很多接受者。 在本篇导航中，我们将为其添加一个特性-我们将使订阅消息的一个子集成为可能。例如，我们能够将错误信息定向写入错误日志文件，同时能够在控制台打印所有信息。 binding在之前的例子中我们能够创建绑定，你可能会回想起这样的代码 1channel.queueBind(queueName, EXCHANGE_NAME, &quot;&quot;); 绑定是交换和队列之间的关系。这可以简单地理解：队列对来自这个交换的消息感兴趣。 绑定可以使用额外的routingKey参数。为了避免与基本的发布参数混淆，我们将其称为绑定键。这就是我们如何键创建绑定的方法。 1channel.queueBind(queueName, EXCHANGE_NAME, &quot;black&quot;); 绑定键的意义取决于交换类型。我们之前使用的fanout交换机完全忽略了它的价值。 Direct exchange我们之前使用的fanoutexchange,这并没有给我们多大的灵活性——它只能进行不需要动脑筋的广播。我们将用directexchange.消息可以传递到其绑定键bindingKey与消息的路由键routingkey完全匹配的队列 我们可以看到，这里面error可以发送到amqp.gen-S9b...和amqp.gen-Ag1...队列中,而info和waring只能发送到amqp.gen-Ag1...队列中 Send.java 1234567891011121314151617public class Send &#123; private static final String EXCHANGE_NAME = \"test_exchange_direct\"; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection = ConnectionUtils.getConnection(); // 创建channle Channel channel = connection.createChannel(); // 声明exchange channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.DIRECT); String msg = \"hello exchange direct\"; String routingKey = \"error\"; channel.basicPublish(EXCHANGE_NAME, routingKey, null, msg.getBytes()); channel.close(); connection.close(); &#125;&#125; Rece1.java 1234567891011121314151617181920212223242526272829303132public class Rece1 &#123; private static final String EXCHANGE_NAME = \"test_exchange_direct\"; private static final String QUEUE_NAME = \"test_queue_direct1\"; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection = ConnectionUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME,false,false,false,null); channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,\"error\"); channel.basicQos(1); Consumer consumer = new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body,\"utf-8\"); System.out.println(\"rece1 recieve msg :\" + msg); try&#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; System.out.println(\"rece1 done\"); channel.basicAck(envelope.getDeliveryTag(),false); &#125; &#125; &#125;; channel.basicConsume(QUEUE_NAME,false,consumer); &#125;&#125; Rece2.java 123456789101112131415161718192021222324252627282930public class Rece1 &#123; private static final String EXCHANGE_NAME = \"test_exchange_direct\"; private static final String QUEUE_NAME = \"test_queue_direct1\"; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection = ConnectionUtils.getConnection(); Channel channel = connection.createChannel(); channel.queueDeclare(QUEUE_NAME,false,false,false,null); channel.queueBind(QUEUE_NAME,EXCHANGE_NAME,\"error\"); channel.basicQos(1); Consumer consumer = new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body,\"utf-8\"); System.out.println(\"rece1 recieve msg :\" + msg); try&#123; TimeUnit.SECONDS.sleep(2); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; System.out.println(\"rece1 done\"); channel.basicAck(envelope.getDeliveryTag(),false); &#125; &#125; &#125;; channel.basicConsume(QUEUE_NAME,false,consumer); &#125;&#125; 偶尔报错队列绑定交换机时，routingKey是具有缓存机制的。我在写代码的时候，误操作了将队列都绑定了error，info,warning.我发现无法实现上述的效果，改了代码，但是还是无法解决。最后登录了RabbitMQ查看相关绑定。并使用的unbind功能。","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/categories/rabbitmq/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"}]},{"title":"RabbitMQ-发布/订阅","slug":"RabbitMQ-发布-订阅","date":"2020-03-01T09:23:16.000Z","updated":"2020-03-11T07:22:28.053Z","comments":true,"path":"2020/03/01/RabbitMQ-发布-订阅/","link":"","permalink":"http://yoursite.com/2020/03/01/RabbitMQ-%E5%8F%91%E5%B8%83-%E8%AE%A2%E9%98%85/","excerpt":"","text":"发布与订阅在上一个教程中，我们创建一个工作队列，我们将每个人物，最终恰好分配到一个工人。然而，在这个部分，我们希望每个消息能分配给多个消费者。这种叫发布订阅模式。举例，注册时需要同时发送短信和发送email,我们会将用户注册的信息发给两个消费者，一个专门发送短信消费者，一个专门发送email消费者。 RabbitMQ消息传递模型的核心思想是，生产者不直接想消息队列发送信息。实际上，生产者并不知道消息是否会被传递到任何队列上。 交换机这里就讲到一个新型概念，交换机（exchange）,一方面接收生产者的信息，一方面推送给队列。交换器必须确切地知道如何处理它接收到的消息。它应该被附加到一个特定的队列吗?它应该被添加到许多队列中吗?或者它应该被丢弃。这些规则由exchange类型定义。有几种可用的交换类型:direct、topic、headers和fanout。下面讲：fanout，是一个比较简单的类型。只是将消息广播到它知道的所有队列中去。下图中X就是交换机。 生产者12345678910111213141516public class Send &#123; private final static String EXCHANGE_NAME &#x3D; &quot;test_exchange_fanout&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection &#x3D; ConnectionUtils.getConnection() ; Channel channel &#x3D; connection.createChannel(); &#x2F;&#x2F; 声明队列 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT);&#x2F;&#x2F;分发类型fanout String msg &#x3D; &quot;hello world ps&quot;; &#x2F;&#x2F; 发送信息 channel.basicPublish(EXCHANGE_NAME,&quot;&quot;,null,msg.getBytes()); System.out.println(&quot;send success&quot;); &#x2F;&#x2F; 关闭流 channel.close(); connection.close(); &#125;&#125; 消费者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Rece1 &#123; private final static String QUEUE_NAME &#x3D; &quot;test_queu_email&quot;; private final static String EXCHANGE_NAME &#x3D; &quot;test_exchange_fanout&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection &#x3D; ConnectionUtils.getConnection(); Channel channel &#x3D; connection.createChannel(); &#x2F;&#x2F; 绑定队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); &#x2F;&#x2F; 绑定队列到交换机上 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;&quot;); &#x2F;&#x2F;qos&#x3D;1 channel.basicQos(1); DefaultConsumer consumer &#x3D; new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;send email &quot; + new String(body, Charset.defaultCharset())); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;; boolean autoAck &#x3D; false; channel.basicConsume(QUEUE_NAME, autoAck, consumer); &#125;&#125;public class Rece2 &#123; private final static String QUEUE_NAME &#x3D; &quot;test_queu_msg&quot;; private final static String EXCHANGE_NAME &#x3D; &quot;test_exchange_fanout&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection &#x3D; ConnectionUtils.getConnection(); Channel channel &#x3D; connection.createChannel(); &#x2F;&#x2F; 绑定队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); &#x2F;&#x2F; 绑定队列到交换机上 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;&quot;); &#x2F;&#x2F;qos&#x3D;1 channel.basicQos(1); DefaultConsumer consumer &#x3D; new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;send msg &quot; + new String(body, Charset.defaultCharset())); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;; boolean autoAck &#x3D; false; channel.basicConsume(QUEUE_NAME, autoAck, consumer); &#125;&#125; 官方推荐的queue_name官方希望能够实现，生成唯一名称queue_name,并且一旦断开生产者连接，队列自动删除。 1String queueName &#x3D; channel.queueDeclare().getQueue();","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/categories/rabbitmq/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"}]},{"title":"工作队列","slug":"工作队列","date":"2020-02-20T10:01:40.000Z","updated":"2020-03-11T07:22:27.993Z","comments":true,"path":"2020/02/20/工作队列/","link":"","permalink":"http://yoursite.com/2020/02/20/%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97/","excerpt":"","text":"介绍RabbitMQ是消息代理。它接收信息和转发信息。你可以把他考虑成一个邮局。当你讲邮寄的信放在邮局时，你可以确定邮差先生或者女士会把邮件最终送到你的收件人手中。当然邮局和RabbitMQ最大的区别，RabbitMq不接受纸张，它只接收，存储，转发二进制的数据消息快。 下面讲一些RabbitMQ中的术语： Producer 生成只不过意味着发送信息。发送信息的程序是生产者 Queue 队列是驻留在RabbitMQ内的邮箱的名称。尽管消息flow RabbitMQ和你的程序，但是他们只能存储在队列中。一个队列只受主机的内存和磁盘限制，它的本质是一个大的消息缓冲区。许多消费者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据，这就我们表示队列的方式。 Consumer 消费和接收有相同的意义。消费者是一个主要接收消息的程序 注意：生产者、消费者和代理不必都在同一主机上；实际上，在大多数应用程序中，它们并没有这样做。应用程序既可以是生成者也可以是消费者。 简单队列简单队列，就是发送单个消息的消费者和接收信息并将其打印出来的使用者（消费者），不多叙述。 工作队列工作队列主要是避免短时间内执行密集任务，并且必须等待它完成。我们将任务放在消息队列中，启动多个消费者，任务在他们中是共享的。 设计到工作队列，当然会有不同方式的工作队列 ack关于ack这边多讲一点，message acknowledgment是消息确认，设置autoack=true之后，consumer返回一个ack（nowledgement）,告诉rabbitMQ已经接受信息，处理了特定的消息，RabbitMQ可以自由地删除它。 轮询队列（Round-robin dispatching）将autoAck设置为true,默认情况下，RabbitMQ会发送每条信息给另一个消费者。每个消费者都会获取相同数量的。并且是间隔形式的。如有c1,c2消费者，10条消息，c1是0,2,4,6,8，c2是1,3,5,7,9。当然，在我打断点时，发现对应的数据会都一次性发送到c1，和c2，c1和c2处理信息时，并不影响彼此。 公平队列在RabbitMQ分发信息的时候，可能会发现，一个consumer很忙，另一个一点也不忙。因为RabbitMQ对此一无所知，只是将第N条信息，发送给第Nconsumer. 为了解决这个，我们将basicQos方法和prefetechCount=1设置一起用。换句话说，在处理并确认上一条信息之前，不要将新信息发送给工人。 12int prefetchCount = 1;channel.basicQos(prefetchCount); 并且，我们需要将autoAck设为false和处理完一条消息后发送ack给RabbitMQ 12345678910111213141516DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, \"utf-8\"); System.out.println(\"receive1 : \" + msg); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; channel.basicAck(envelope.getDeliveryTag(),false); &#125; &#125; &#125;; boolean autoack = false; channel.basicConsume(QUEUE_NAME,autoack,defaultConsumer);","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/categories/rabbitmq/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"}]},{"title":"0109 什么是微服务","slug":"0109-什么是微服务","date":"2020-01-10T03:52:53.000Z","updated":"2020-01-10T06:32:53.291Z","comments":true,"path":"2020/01/10/0109-什么是微服务/","link":"","permalink":"http://yoursite.com/2020/01/10/0109-%E4%BB%80%E4%B9%88%E6%98%AF%E5%BE%AE%E6%9C%8D%E5%8A%A1/","excerpt":"微服务架构风格，就像是把一个单独的应用程序开发为一套小服务，每个小服务运行在自己的进程中，并使用轻量级机制通信，通常是HTTP API.这些服务围绕业务能力来构建，并通过完全自动化部署机制来独立部署。这些服务使用不同的编程语言书写，以及不同数据存储技术，并保持最低限度的集中式管理。","text":"微服务架构风格，就像是把一个单独的应用程序开发为一套小服务，每个小服务运行在自己的进程中，并使用轻量级机制通信，通常是HTTP API.这些服务围绕业务能力来构建，并通过完全自动化部署机制来独立部署。这些服务使用不同的编程语言书写，以及不同数据存储技术，并保持最低限度的集中式管理。 微服务为什么要使用Spring Cloud从使用nginx说起最初的服务化解决方案是给提供相同服务提供一个统一的域名，然后服务调用者向这个域名发送HTTP请求，由Nginx负责请求的分发和跳转 但是这样有不少缺点: Nginx作为中间层，在配置文件中耦合了服务调用的逻辑，这削弱了微服务的完整性，也使得Nginx在一定程度上变成了一个重量级的ESB. 服务的信息分散在各个系统，无法统一管理和维护。每一次的服务调用都是一次尝试，服务消费者并不知道有哪些实例在给他们提供服务。这不符合DevOps的理念。 无法直观的看到服务提供者和服务消费者当前的运行和通信频率。这也不符合DevOps的理念。 消费者的失败重发，负载均衡等都没有统一策略，这加大了开发每个服务的难度，不利于快熟演化。 为了解决上面的问题，我们需要一个现成的中心化组件对服务进行整合，将每个服务的信息整合，包括服务的组件名称、地址、数量等。服务的调用方在请求每项服务时首先通过中心组件获取提供这项服务的实例的信息（IP、端口等），再通过默认或自定义的策略选择该服务的某一提供者直接进行访问，所以我们引入了Dubbo。 基于Dubbo实现微服务Dubbo是阿里开源的一个SOA服务治理解决方案，文档丰富，在国内的使用度非常高。 使用Dubbo构建的微服务，已经比较好地解决上面提到的问题： 调用中间层变成了可选组件，消费者可以直接访问服务提供者 服务信息被集中到Registry中，形成了服务治理的中心组件。 通过Monitor监控系统，可以直观地展示服务调用的统计信息。 Consumer可以进行负载均衡、服务降级的选择 但是对于微服务架构而言，Dubbo也并不是十全十美的： Registry严重依赖第三方组件（Zookeeper或者redis），当这些组件出现问题，服务调用很快就会中断（当然，我之前也试过中断时，会有缓存还是可以调用） Dubbo只支持RPC调用。使得服务提供方与调用方在代码上产生了强依赖，服务提供者需要不断将包含公共代码的jar包打包出来供消费者使用。一旦打包出现问题，就会导致服务调用出现问题（公共代码是指 包含公共配置：DO(和数据库同步，用于持久化对象)，VO(传输数据)，工具包，接口等） 新的选择–Spring clouddubbo和spring cloud 区别 Dubbo Spring Cloud 服务注册中心 Zookeeper Spring Cloud Netflix Eureka 服务调用方式 RPC REST API 服务监控 Dubbo-monitor Spring Boot Admin 断路器 不完善 Spring Cloud Netflix Hystrix 服务网关 无 Spring Cloud Netflix Zuul 分布式配置 无 Spring Cloud Config 服务跟踪 无 Spring Cloud Sleuth 消息总线 无 Spring Cloud Bus 数据流 无 Spring Cloud Stream 批量任务 无 Spring Cloud Task 服务调用方式：Spring Cloud 抛弃了Dubbo的RPC通信，采用的是基于HTTP的REST方式。严格来说，这两种各有优劣。虽然从一定程度上来说，后者牺牲了服务调用的性能，但也避免了上面提到的原生RPC带来的问题。而且REST相比RPC更为灵活，服务提供方和调用的依赖只依赖一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更加合适。","categories":[{"name":"Spring cloud","slug":"Spring-cloud","permalink":"http://yoursite.com/categories/Spring-cloud/"}],"tags":[{"name":"Spring cloud","slug":"Spring-cloud","permalink":"http://yoursite.com/tags/Spring-cloud/"}]},{"title":"hexo大致教程","slug":"hexo","date":"2020-01-10T03:16:18.000Z","updated":"2020-03-09T10:42:24.917Z","comments":true,"path":"2020/01/10/hexo/","link":"","permalink":"http://yoursite.com/2020/01/10/hexo/","excerpt":"","text":"步骤 安装npm,并配置淘宝镜像 下载hexo 1$ npm install -g hexo-cli 修改theme 12教程 https:&#x2F;&#x2F;xaoxuu.com&#x2F;wiki&#x2F;material-x&#x2F;index.html完成后： 修改_config.yml中的theme配置 部署到用户名.github.io 12345大致教程： https:&#x2F;&#x2F;www.bilibili.com&#x2F;read&#x2F;cv2204874&#x2F;新建md： hexo new 文件名会在&#x2F;source&#x2F;_posts&#x2F;文件名.mdhexo d -g","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-01-10T02:35:18.889Z","updated":"2020-01-10T02:35:18.889Z","comments":true,"path":"2020/01/10/hello-world/","link":"","permalink":"http://yoursite.com/2020/01/10/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}