{"meta":{"title":"huskyui","subtitle":"","description":"","author":"huskyui","url":"http://yoursite.com","root":"/"},"pages":[],"posts":[{"title":"'RabbitMQ-发布/订阅'","slug":"RabbitMQ-发布-订阅","date":"2020-03-01T09:23:16.000Z","updated":"2020-03-09T10:29:36.425Z","comments":true,"path":"2020/03/01/RabbitMQ-发布-订阅/","link":"","permalink":"http://yoursite.com/2020/03/01/RabbitMQ-%E5%8F%91%E5%B8%83-%E8%AE%A2%E9%98%85/","excerpt":"","text":"发布与订阅在上一个教程中，我们创建一个工作队列，我们将每个人物，最终恰好分配到一个工人。然而，在这个部分，我们希望每个消息能分配给多个消费者。这种叫发布订阅模式。举例，注册时需要同时发送短信和发送email,我们会将用户注册的信息发给两个消费者，一个专门发送短信消费者，一个专门发送email消费者。 RabbitMQ消息传递模型的核心思想是，生产者不直接想消息队列发送信息。实际上，生产者并不知道消息是否会被传递到任何队列上。 交换机这里就讲到一个新型概念，交换机（exchange）,一方面接收生产者的信息，一方面推送给队列。交换器必须确切地知道如何处理它接收到的消息。它应该被附加到一个特定的队列吗?它应该被添加到许多队列中吗?或者它应该被丢弃。这些规则由exchange类型定义。有几种可用的交换类型:direct、topic、headers和fanout。下面讲：fanout，是一个比较简单的类型。只是将消息广播到它知道的所有队列中去。下图中X就是交换机。 生产者12345678910111213141516public class Send &#123; private final static String EXCHANGE_NAME &#x3D; &quot;test_exchange_fanout&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection &#x3D; ConnectionUtils.getConnection() ; Channel channel &#x3D; connection.createChannel(); &#x2F;&#x2F; 声明队列 channel.exchangeDeclare(EXCHANGE_NAME, BuiltinExchangeType.FANOUT);&#x2F;&#x2F;分发类型fanout String msg &#x3D; &quot;hello world ps&quot;; &#x2F;&#x2F; 发送信息 channel.basicPublish(EXCHANGE_NAME,&quot;&quot;,null,msg.getBytes()); System.out.println(&quot;send success&quot;); &#x2F;&#x2F; 关闭流 channel.close(); connection.close(); &#125;&#125; 消费者12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class Rece1 &#123; private final static String QUEUE_NAME &#x3D; &quot;test_queu_email&quot;; private final static String EXCHANGE_NAME &#x3D; &quot;test_exchange_fanout&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection &#x3D; ConnectionUtils.getConnection(); Channel channel &#x3D; connection.createChannel(); &#x2F;&#x2F; 绑定队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); &#x2F;&#x2F; 绑定队列到交换机上 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;&quot;); &#x2F;&#x2F;qos&#x3D;1 channel.basicQos(1); DefaultConsumer consumer &#x3D; new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;send email &quot; + new String(body, Charset.defaultCharset())); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;; boolean autoAck &#x3D; false; channel.basicConsume(QUEUE_NAME, autoAck, consumer); &#125;&#125;public class Rece2 &#123; private final static String QUEUE_NAME &#x3D; &quot;test_queu_msg&quot;; private final static String EXCHANGE_NAME &#x3D; &quot;test_exchange_fanout&quot;; public static void main(String[] args) throws IOException, TimeoutException &#123; Connection connection &#x3D; ConnectionUtils.getConnection(); Channel channel &#x3D; connection.createChannel(); &#x2F;&#x2F; 绑定队列 channel.queueDeclare(QUEUE_NAME, false, false, false, null); &#x2F;&#x2F; 绑定队列到交换机上 channel.queueBind(QUEUE_NAME, EXCHANGE_NAME, &quot;&quot;); &#x2F;&#x2F;qos&#x3D;1 channel.basicQos(1); DefaultConsumer consumer &#x3D; new DefaultConsumer(channel) &#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; System.out.println(&quot;send msg &quot; + new String(body, Charset.defaultCharset())); channel.basicAck(envelope.getDeliveryTag(), false); &#125; &#125;; boolean autoAck &#x3D; false; channel.basicConsume(QUEUE_NAME, autoAck, consumer); &#125;&#125; 官方推荐的queue_name官方希望能够实现，生成唯一名称queue_name,并且一旦断开生产者连接，队列自动删除。 1String queueName &#x3D; channel.queueDeclare().getQueue();","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/categories/rabbitmq/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"}]},{"title":"工作队列","slug":"工作队列","date":"2020-02-20T10:01:40.000Z","updated":"2020-03-01T09:23:52.293Z","comments":true,"path":"2020/02/20/工作队列/","link":"","permalink":"http://yoursite.com/2020/02/20/%E5%B7%A5%E4%BD%9C%E9%98%9F%E5%88%97/","excerpt":"","text":"介绍RabbitMQ是消息代理。它接收信息和转发信息。你可以把他考虑成一个邮局。当你讲邮寄的信放在邮局时，你可以确定邮差先生或者女士会把邮件最终送到你的收件人手中。当然邮局和RabbitMQ最大的区别，RabbitMq不接受纸张，它只接收，存储，转发二进制的数据消息快。 下面讲一些RabbitMQ中的术语： Producer 生成只不过意味着发送信息。发送信息的程序是生产者 Queue 队列是驻留在RabbitMQ内的邮箱的名称。尽管消息flow RabbitMQ和你的程序，但是他们只能存储在队列中。一个队列只受主机的内存和磁盘限制，它的本质是一个大的消息缓冲区。许多消费者可以将消息发送到一个队列，许多消费者可以尝试从一个队列接收数据，这就我们表示队列的方式。 Consumer 消费和接收有相同的意义。消费者是一个主要接收消息的程序 注意：生产者、消费者和代理不必都在同一主机上；实际上，在大多数应用程序中，它们并没有这样做。应用程序既可以是生成者也可以是消费者。 简单队列简单队列，就是发送单个消息的消费者和接收信息并将其打印出来的使用者（消费者），不多叙述。 工作队列工作队列主要是避免短时间内执行密集任务，并且必须等待它完成。我们将任务放在消息队列中，启动多个消费者，任务在他们中是共享的。 设计到工作队列，当然会有不同方式的工作队列 ack关于ack这边多讲一点，message acknowledgment是消息确认，设置autoack=true之后，consumer返回一个ack（nowledgement）,告诉rabbitMQ已经接受信息，处理了特定的消息，RabbitMQ可以自由地删除它。 轮询队列（Round-robin dispatching）将autoAck设置为true,默认情况下，RabbitMQ会发送每条信息给另一个消费者。每个消费者都会获取相同数量的。并且是间隔形式的。如有c1,c2消费者，10条消息，c1是0,2,4,6,8，c2是1,3,5,7,9。当然，在我打断点时，发现对应的数据会都一次性发送到c1，和c2，c1和c2处理信息时，并不影响彼此。 公平队列在RabbitMQ分发信息的时候，可能会发现，一个consumer很忙，另一个一点也不忙。因为RabbitMQ对此一无所知，只是将第N条信息，发送给第Nconsumer. 为了解决这个，我们将basicQos方法和prefetechCount=1设置一起用。换句话说，在处理并确认上一条信息之前，不要将新信息发送给工人。 12int prefetchCount = 1;channel.basicQos(prefetchCount); 并且，我们需要将autoAck设为false和处理完一条消息后发送ack给RabbitMQ 12345678910111213141516DefaultConsumer defaultConsumer = new DefaultConsumer(channel)&#123; @Override public void handleDelivery(String consumerTag, Envelope envelope, AMQP.BasicProperties properties, byte[] body) throws IOException &#123; String msg = new String(body, \"utf-8\"); System.out.println(\"receive1 : \" + msg); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125;finally &#123; channel.basicAck(envelope.getDeliveryTag(),false); &#125; &#125; &#125;; boolean autoack = false; channel.basicConsume(QUEUE_NAME,autoack,defaultConsumer);","categories":[{"name":"rabbitmq","slug":"rabbitmq","permalink":"http://yoursite.com/categories/rabbitmq/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"}]},{"title":"0109 什么是微服务","slug":"0109-什么是微服务","date":"2020-01-10T03:52:53.000Z","updated":"2020-01-10T06:32:53.291Z","comments":true,"path":"2020/01/10/0109-什么是微服务/","link":"","permalink":"http://yoursite.com/2020/01/10/0109-%E4%BB%80%E4%B9%88%E6%98%AF%E5%BE%AE%E6%9C%8D%E5%8A%A1/","excerpt":"微服务架构风格，就像是把一个单独的应用程序开发为一套小服务，每个小服务运行在自己的进程中，并使用轻量级机制通信，通常是HTTP API.这些服务围绕业务能力来构建，并通过完全自动化部署机制来独立部署。这些服务使用不同的编程语言书写，以及不同数据存储技术，并保持最低限度的集中式管理。","text":"微服务架构风格，就像是把一个单独的应用程序开发为一套小服务，每个小服务运行在自己的进程中，并使用轻量级机制通信，通常是HTTP API.这些服务围绕业务能力来构建，并通过完全自动化部署机制来独立部署。这些服务使用不同的编程语言书写，以及不同数据存储技术，并保持最低限度的集中式管理。 微服务为什么要使用Spring Cloud从使用nginx说起最初的服务化解决方案是给提供相同服务提供一个统一的域名，然后服务调用者向这个域名发送HTTP请求，由Nginx负责请求的分发和跳转 但是这样有不少缺点: Nginx作为中间层，在配置文件中耦合了服务调用的逻辑，这削弱了微服务的完整性，也使得Nginx在一定程度上变成了一个重量级的ESB. 服务的信息分散在各个系统，无法统一管理和维护。每一次的服务调用都是一次尝试，服务消费者并不知道有哪些实例在给他们提供服务。这不符合DevOps的理念。 无法直观的看到服务提供者和服务消费者当前的运行和通信频率。这也不符合DevOps的理念。 消费者的失败重发，负载均衡等都没有统一策略，这加大了开发每个服务的难度，不利于快熟演化。 为了解决上面的问题，我们需要一个现成的中心化组件对服务进行整合，将每个服务的信息整合，包括服务的组件名称、地址、数量等。服务的调用方在请求每项服务时首先通过中心组件获取提供这项服务的实例的信息（IP、端口等），再通过默认或自定义的策略选择该服务的某一提供者直接进行访问，所以我们引入了Dubbo。 基于Dubbo实现微服务Dubbo是阿里开源的一个SOA服务治理解决方案，文档丰富，在国内的使用度非常高。 使用Dubbo构建的微服务，已经比较好地解决上面提到的问题： 调用中间层变成了可选组件，消费者可以直接访问服务提供者 服务信息被集中到Registry中，形成了服务治理的中心组件。 通过Monitor监控系统，可以直观地展示服务调用的统计信息。 Consumer可以进行负载均衡、服务降级的选择 但是对于微服务架构而言，Dubbo也并不是十全十美的： Registry严重依赖第三方组件（Zookeeper或者redis），当这些组件出现问题，服务调用很快就会中断（当然，我之前也试过中断时，会有缓存还是可以调用） Dubbo只支持RPC调用。使得服务提供方与调用方在代码上产生了强依赖，服务提供者需要不断将包含公共代码的jar包打包出来供消费者使用。一旦打包出现问题，就会导致服务调用出现问题（公共代码是指 包含公共配置：DO(和数据库同步，用于持久化对象)，VO(传输数据)，工具包，接口等） 新的选择–Spring clouddubbo和spring cloud 区别 Dubbo Spring Cloud 服务注册中心 Zookeeper Spring Cloud Netflix Eureka 服务调用方式 RPC REST API 服务监控 Dubbo-monitor Spring Boot Admin 断路器 不完善 Spring Cloud Netflix Hystrix 服务网关 无 Spring Cloud Netflix Zuul 分布式配置 无 Spring Cloud Config 服务跟踪 无 Spring Cloud Sleuth 消息总线 无 Spring Cloud Bus 数据流 无 Spring Cloud Stream 批量任务 无 Spring Cloud Task 服务调用方式：Spring Cloud 抛弃了Dubbo的RPC通信，采用的是基于HTTP的REST方式。严格来说，这两种各有优劣。虽然从一定程度上来说，后者牺牲了服务调用的性能，但也避免了上面提到的原生RPC带来的问题。而且REST相比RPC更为灵活，服务提供方和调用的依赖只依赖一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更加合适。","categories":[{"name":"Spring cloud","slug":"Spring-cloud","permalink":"http://yoursite.com/categories/Spring-cloud/"}],"tags":[{"name":"Spring cloud","slug":"Spring-cloud","permalink":"http://yoursite.com/tags/Spring-cloud/"}]},{"title":"hexo大致教程","slug":"hexo","date":"2020-01-10T03:16:18.000Z","updated":"2020-01-10T03:48:58.483Z","comments":true,"path":"2020/01/10/hexo/","link":"","permalink":"http://yoursite.com/2020/01/10/hexo/","excerpt":"","text":"步骤 安装npm,并配置淘宝镜像 下载hexo 1$ npm install -g hexo-cli 修改theme 12教程 https:&#x2F;&#x2F;xaoxuu.com&#x2F;wiki&#x2F;material-x&#x2F;index.html完成后： 修改_config.yml中的theme配置 部署到用户名.github.io 12345大致教程： https:&#x2F;&#x2F;www.bilibili.com&#x2F;read&#x2F;cv2204874&#x2F;新建md： hexo new &#39;文件名&#39;会在&#x2F;source&#x2F;_posts&#x2F;文件名.mdhexo d -g","categories":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/categories/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"}]},{"title":"Hello World","slug":"hello-world","date":"2020-01-10T02:35:18.889Z","updated":"2020-01-10T02:35:18.889Z","comments":true,"path":"2020/01/10/hello-world/","link":"","permalink":"http://yoursite.com/2020/01/10/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]}]}